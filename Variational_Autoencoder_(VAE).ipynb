{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oki9byQX2bgC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"device=\", device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def variational_loss(mu, std):\n",
        "    #returns the varialtional loss from arguments mean and standard deviation std\n",
        "    #see also: see Appendix B from VAE paper:\n",
        "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
        "    #https://arxiv.org/abs/1312.6114\n",
        "    vl=-0.5*torch.mean(1+ 2*torch.log(std)-mu.pow(2) -(std.pow(2)))\n",
        "    return vl\n",
        "\n",
        "def variational_loss2(mu, std):\n",
        "    #returns the varialtional loss from arguments mean and standard deviation std\n",
        "    #alternative: mean squared distance from ideal mu=0 and std=1:\n",
        "    vl=torch.mean(mu.pow(2)+(1-std).pow(2))\n",
        "    return vl"
      ],
      "metadata": {
        "id": "1rpeqZkv7EbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing:\n",
        "#compare the variational losses for different standard deviations std and mu=0:\n",
        "std=np.arange(0,20)\n",
        "vloss=torch.zeros(std.shape)\n",
        "vloss2=torch.zeros(std.shape)\n",
        "for std_ in std:\n",
        "    vloss[std_]=variational_loss(torch.tensor([0.0]),torch.tensor(0.1*std_))\n",
        "    vloss2[std_]=variational_loss2(torch.tensor([0.0]),torch.tensor([0.1*std_]))\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(0.1*std,np.array(vloss))\n",
        "plt.plot(0.1*std,np.array(vloss2))\n",
        "plt.ylabel('Loss Value')\n",
        "plt.xlabel('Standard Deviation')\n",
        "plt.title('Variational Losses for mu=0')\n",
        "plt.legend(('Standard VAE Loss', 'Mean Squared Distance from ideal Loss'))\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "osyNNKxz7GeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n",
        "import scipy.io.wavfile as wav"
      ],
      "metadata": {
        "id": "XzB5OOfd7RAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if sys.version_info[0] < 3:\n",
        "    # for Python 2\n",
        "    import cPickle as pickle\n",
        "else:\n",
        "    # for Python 3\n",
        "    import pickle\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"device=\", device)"
      ],
      "metadata": {
        "id": "jObpCtZf7TNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def signal2pytorch(x):\n",
        "    #Function to convert a signal vector x, like a mono audio signal, into a 3-d Tensor that conv1d of Pytorch expects,\n",
        "    #https://pytorch.org/docs/stable/nn.html\n",
        "    #Argument x: a 1-d signal as numpy array\n",
        "    #input x[batch,sample]\n",
        "    #output: 3-d Tensor X for conv1d input.\n",
        "    #for conv1d Input: (N,Cin,Lin), Cin: numer of input channels (e.g. for stereo), Lin: length of signal, N: number of Batches (signals)\n",
        "    X = np.expand_dims(x, axis=0)  #add channels dimension (here only 1 channel)\n",
        "    if len(x.shape)==1: #mono:\n",
        "        X = np.expand_dims(X, axis=0)  #add batch dimension (here only 1 batch)\n",
        "    X=torch.from_numpy(X)\n",
        "    X=X.type(torch.Tensor)\n",
        "    X=X.permute(1,0,2)  #make batch dimension first\n",
        "    return X"
      ],
      "metadata": {
        "id": "VDsHyhzs7U7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Convautoenc(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Convautoenc, self).__init__()\n",
        "        #Analysis Filterbank with downsampling of N=8*1024, filter length of 2N, but only 32 outputs:\n",
        "        #for the mean values:\n",
        "        self.conv1mean=nn.Conv1d(in_channels=1, out_channels=32, kernel_size=8*2048, stride=8*1024, padding=8*1024-1, bias=True) #Padding for 'same' filters (kernel_size/2-1)\n",
        "        #for the standard devieation values:\n",
        "        self.conv1std=nn.Conv1d(in_channels=1, out_channels=32, kernel_size=8*2048, stride=8*1024, padding=8*1024-1, bias=True) #Padding for 'same' filters (kernel_size/2-1)\n",
        "\n",
        "        #Synthesis filter bank:\n",
        "        self.synconv1=nn.ConvTranspose1d(in_channels=32, out_channels=1, kernel_size=8*2048, stride=8*1024, padding=8*1024-1, bias=True)\n",
        "\n",
        "    def encodermean(self, x):\n",
        "        #Analysis:\n",
        "        x = self.conv1mean(x)\n",
        "        y = torch.tanh(x)\n",
        "        return y\n",
        "\n",
        "    def encoderstd(self, x):\n",
        "        #Analysis:\n",
        "        x = self.conv1std(x)\n",
        "        y = torch.abs(torch.tanh(x))\n",
        "        return y\n",
        "\n",
        "    def decoder(self, y):\n",
        "        #Synthesis:\n",
        "        xrek= self.synconv1(y)\n",
        "        return xrek\n",
        "\n",
        "    def forward(self, x):\n",
        "        Yencmean=model.encodermean(x)\n",
        "        Yencstd=model.encoderstd(x)\n",
        "        #Yvariational= torch.normal(Yencmean, Yencstd)\n",
        "        Yvariational= Yencmean + Yencstd*torch.randn_like(Yencstd)\n",
        "        #for the randn_like see also: https://github.com/pytorch/examples/blob/master/vae/main.py\n",
        "        Ypred=model.decoder(Yvariational)\n",
        "        return Ypred, Yencmean, Yencstd"
      ],
      "metadata": {
        "id": "k45sGrjM7Yn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def variational_loss(mu, std):\n",
        "    #returns the varialtional loss from arguments mean and standard deviation std\n",
        "    #see also: see Appendix B from VAE paper:\n",
        "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
        "    #https://arxiv.org/abs/1312.6114\n",
        "    vl=-0.5*torch.mean(1+ 2*torch.log(std)-mu.pow(2) -(std.pow(2)))\n",
        "    return vl\n",
        "\n",
        "def variational_loss2(mu, std):\n",
        "    #returns the varialtional loss from arguments mean and standard deviation std\n",
        "    #alternative: mean squared distance from ideal mu=0 and std=1:\n",
        "    vl=torch.mean(mu.pow(2)+(1-std).pow(2))\n",
        "    return vl"
      ],
      "metadata": {
        "id": "ppdfQJ2E7aX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa"
      ],
      "metadata": {
        "id": "ao_ua_c37b-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#alternative: speech:\n",
        "#make training set with batch of 2 speech signals:\n",
        "batch=2;\n",
        "#fs, x0= wav.read('./audio/test2.wav') #get size of the speech files, all need to be identical\n",
        "x0, fs = librosa.load(\"./audio/Iron Maiden - The Number Of The Beast.mp3\", mono=True, sr=None, duration=6, offset=13)\n",
        "xlen=max(x0.shape)\n",
        "x=np.zeros((batch,xlen))\n",
        "for b in range(batch):\n",
        "    if b==0:\n",
        "        #fs, x0= wav.read('./audio/test2.wav')\n",
        "        x0, fs = librosa.load(\"./audio/Iron Maiden - The Number Of The Beast.mp3\", mono=True, sr=None, duration=6, offset=13)\n",
        "    if b==1:\n",
        "        #fs, x0= wav.read('./audio/test3.wav')\n",
        "        x0, fs = librosa.load(\"./audio/Iron Maiden - Aces High.mp3\", mono=True, sr=None, duration=6, offset=8)\n",
        "    x0= x0/max(x0)\n",
        "    x[b,:]=x0\n",
        "    #x=x*1.0/2**15 #normalize\n",
        "    print(\"x.shape=\", x.shape)\n",
        "    X=signal2pytorch(x).to(device) #Convert to pytorch format, batch is first dimension\n",
        "    print(\"X.shape=\", X.shape)\n",
        "    print(\"Generate Model:\")\n",
        "    model = Convautoenc().to(device)\n",
        "    print('Total number of parameters: %i' % (sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
        "    print(\"Def. loss function:\")\n",
        "    loss_fn = nn.MSELoss()  #MSE"
      ],
      "metadata": {
        "id": "QwhX3Mfp7eHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ypred, Yencmean, Yencstd = model(X)\n",
        "\n",
        "#Ypred=Ypred.detach()\n",
        "outputlen=len(Ypred[0,0,:]) #length of the signal at the output of the network.\n",
        "print(\"outputlen=\", outputlen)\n",
        "\n",
        "Y=X[:,:,:outputlen]  #the target signal with same length as model output\n",
        "\n",
        "print(\"Input X.shape=\", X.shape )\n",
        "print(\"Target Y.shape=\", Y.shape)\n",
        "print(\"Target Y=\", Y)\n",
        "#print(\"max(max(Y))=\", max(max(max(Y))))\n",
        "#print(\"min(min(Y))=\", min(min(min(Y))))\n",
        "print(\"Y.type()=\", Y.type())\n",
        "\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)#, betas=(0.9, 0.999))\n",
        "\"\"\"\n",
        "try:\n",
        "    checkpoint = torch.load(\"audio_variational_autoenc.torch\",map_location='cpu')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    #optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "except IOError:\n",
        "    print(\"fresh start\")\n",
        "\"\"\"\n",
        "#optimrandomdir_pytorch.optimizer(model, loss_fn, X, Ypred, iterations=300, startingscale=1.0, endscale=0.0)\n",
        "#Ypred=model(X)\n",
        "#Ypred=Ypred.detach()\n",
        "#print(\"Ypred=\", Ypred)\n",
        "\n",
        "#randdir=True # True for optimization of random direction, False for pytorch optimization\n",
        "randdir=False"
      ],
      "metadata": {
        "id": "-OB2VT5c7hnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Eksperimen 1**"
      ],
      "metadata": {
        "id": "yF2ffR2x7lsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if randdir==True:\n",
        "    #optimization of weights using method of random directions:\n",
        "    optimrandomdir_pytorch.optimizer(model, loss_fn, X, Y, iterations=100000, startingscale=0.25, endscale=0.0)\n",
        "    #--End optimization of random directions------------------------\n",
        "else:\n",
        "    for epoch in range(2000):\n",
        "        #Ypred, Yencmean, Yencstd = model(X)\n",
        "        #mean values from the encoder network:\n",
        "        Yencmean=model.encodermean(X)\n",
        "\n",
        "        #standard deviation values from the network:\n",
        "        Yencstd=model.encoderstd(X)\n",
        "        #unit standard deviation:\n",
        "        #Yencstd=torch.ones(Yencmean.shape)\n",
        "\n",
        "        Yvariational= Yencmean + Yencstd*torch.randn_like(Yencstd)\n",
        "        Ypred=model.decoder(Yvariational)\n",
        "\n",
        "        mse=loss_fn(Ypred, Y)\n",
        "        vl=variational_loss(Yencmean, Yencstd)\n",
        "        #vl=variational_loss2(Yencmean, Yencstd)\n",
        "        loss= mse + 0.01*vl\n",
        "        #loss= mse\n",
        "        if epoch%10==0:\n",
        "             print(epoch, \"mse=\", mse.item(), \"variational loss=\", vl.item())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    #\"\"\"\n",
        "    torch.save({#'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()}, \"audio_variational_autoenc.torch\")\n",
        "    #\"\"\""
      ],
      "metadata": {
        "id": "bBUjySOf7pmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MSE=\", loss_fn(Ypred, Y).item(), \"Variational Loss:\", variational_loss(Yencmean, Yencstd).item())\n",
        "ww = model.state_dict()   #read obtained weights\n",
        "print(\"ww=\", ww)\n",
        "#Plot obtained weights:\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(np.transpose(np.array(ww['conv1mean.weight'][0:1,0,:])))\n",
        "plt.plot(np.transpose(np.array(ww['conv1std.weight'][0:1,0,:])))\n",
        "plt.plot(np.transpose(np.array(ww['synconv1.weight'][0:1,0,:])))\n",
        "plt.legend(('Encoder Analysis filter 0, mean','Encoder Analysis filter 0, std', 'Decoder Filter 0'))\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Value')\n",
        "plt.title('The Encoder and Decoder Filter Coefficients')\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "Jyk6OxIO70Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test on training set:\n",
        "\n",
        "#predictions=model(X).cpu() # Make Predictions based on the obtained weights, on training set\n",
        "#noisy case:\n",
        "#predictions, Yencmean, Yencstd = model(X)\n",
        "Yencmean=model.encodermean(X)\n",
        "\n",
        "#no noise case\n",
        "predclean=model.decoder(Yencmean)\n",
        "predclean=predclean.detach() #no noise case\n",
        "predclean=np.array(predclean)\n",
        "\n",
        "#Add gaussian noise with unit standard deviation to encoded signal:\n",
        "Yvariational= Yencmean + torch.randn_like(Yencmean)\n",
        "predictions=model.decoder(Yvariational)\n",
        "\n",
        "predictions=predictions.detach()\n",
        "predictions=np.array(predictions)\n",
        "Yencmean=np.array(Yencmean.detach())\n",
        "Yencstd=np.array(Yencstd.detach())\n",
        "print(\"Yencstd.shape=\",Yencstd.shape)\n",
        "\n",
        "Y=np.array(Y) #target\n",
        "#print(\"Y=\",Y)\n",
        "print(\"predictions.shape=\", predictions.shape)\n",
        "#convert to numpy:\n",
        "#https://discuss.pytorch.org/t/how-to-transform-variable-into-numpy/104/2"
      ],
      "metadata": {
        "id": "fn8zPJBN7-j1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd"
      ],
      "metadata": {
        "id": "9LRxTPXb8A2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot target signal and output of autoencoder:\n",
        "\n",
        "for b in range(batch):\n",
        "    #print(\"np.reshape(Yencstd[b,:,:],(1,-1))\", np.reshape(Yencstd[b,:,:],(1,-1)))\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.plot(np.reshape(Yencmean[b,:,:],(1,-1))[0,:])\n",
        "    plt.plot(np.reshape(Yencstd[b,:,:],(1,-1))[0,:])\n",
        "    plt.legend(('Encoded Mean', 'Encoded Standard Deviation'))\n",
        "    plt.title('The Encoded Domain, Mean and Standard Deviation')\n",
        "    plt.grid()\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.plot(np.array(Y[b,0,:]))\n",
        "    plt.plot(predictions[b,0,:])\n",
        "    plt.legend(('Target','Predicted'))\n",
        "    plt.title('The Target and Noisy Predicted Signal, batch '+str(b))\n",
        "    plt.xlabel('Sample')\n",
        "    plt.grid()\n",
        "\n",
        "    #No noise case:\n",
        "    xrek=predclean[b,0,:]  #remove unnecessary dimension for playback\n",
        "    xrek=np.clip(xrek, -1.0,1.0)\n",
        "    wav.write('testrekvaeclean'+str(b)+'.wav', fs, np.int16(2**15*xrek))\n",
        "    print('\"The training set output for clean encoded signal for batch'+str(b)+'\"')\n",
        "    display(ipd.Audio(2**15*xrek,rate=fs))\n",
        "\n",
        "    xrek=predictions[b,0,:]  #remove unnecessary dimension for playback\n",
        "    xrek=np.clip(xrek, -1.0,1.0)\n",
        "    wav.write('testrekvae'+str(b)+'.wav', fs, np.int16(2**15*xrek))\n",
        "    print('\"The training set output for noisy encoded signal for batch'+str(b)+'\"')\n",
        "    display(ipd.Audio(2**15*xrek,rate=fs))"
      ],
      "metadata": {
        "id": "PhIoEs4S8I8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test on Verification set:\n",
        "#fs, x= wav.read('test.wav')\n",
        "x, fs = librosa.load(\"./audio/Iron Maiden - Aces High.mp3\", mono=True, sr=None, duration=6, offset=0)\n",
        "#fs, x= wav.read('test2.wav')\n",
        "#x=x*1.0/2**15 #normalize\n",
        "x=x/max(x)\n",
        "\n",
        "print(\"The verification set input to the variational autoencoder\")\n",
        "display(ipd.Audio(2**14*x,rate=fs))\n",
        "X=signal2pytorch(x).to(device)\n",
        "Yencmean=model.encodermean(X)\n",
        "\n",
        "predclean=model.decoder(Yencmean)\n",
        "predclean=predclean.detach() #no noise case\n",
        "predclean=np.array(predclean)\n",
        "\n",
        "#No noise case:\n",
        "xrek=predclean[0,0,:]  #remove unnecessary dimension for playback\n",
        "xrek=np.clip(xrek, -1.0,1.0)\n",
        "wav.write('testvervaeclean'+str(b)+'.wav', fs, np.int16(2**15*xrek))\n",
        "print(\"The verification set output for clean encoded signal\")\n",
        "display(ipd.Audio(2**15*xrek, rate=fs))\n",
        "\n",
        "#Add gaussian noise with unit standard deviation:\n",
        "Yvariational= Yencmean + torch.randn_like(Yencmean)\n",
        "predictions= model.decoder(Yvariational) # Make Predictions based on the obtained weights, on verification set\n",
        "predictions=predictions.detach()\n",
        "predictions=np.array(predictions)\n",
        "b=0\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(np.array(X[b,0,:]))\n",
        "plt.plot(predictions[b,0,:])\n",
        "plt.legend(('Original','Predicted'))\n",
        "plt.title('Verification, the Original and Predicted Signal, batch ')\n",
        "plt.xlabel('Sample')\n",
        "plt.grid()\n",
        "xrek=predictions[:,0,:]\n",
        "xrek=np.transpose(xrek)\n",
        "xrek=np.clip(xrek, -1.0,1.0)\n",
        "wav.write('testver.wav', fs, np.int16(2**15*xrek))\n",
        "print(\"The verification set output for noisy encoded signal\")\n",
        "display(ipd.Audio('testver.wav', rate=fs))\n",
        "print(\"Only noise as encoded signal\")\n",
        "\n",
        "Yvariational=  torch.randn_like(Yencmean)\n",
        "predictions= model.decoder(Yvariational) # Make Predictions based on the obtained weights, on verification set\n",
        "predictions=predictions.detach()\n",
        "predictions=np.array(predictions)\n",
        "xrek=predictions[:,0,:]\n",
        "xrek=np.transpose(xrek)\n",
        "xrek=np.clip(xrek, -1.0,1.0)\n",
        "wav.write('noisevarout.wav', fs, np.int16(2**15*xrek))\n",
        "print(\"The decoded signal\")\n",
        "display(ipd.Audio('noisevarout.wav', rate=fs))"
      ],
      "metadata": {
        "id": "PGP7CbYb8PPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Eksperimen 2**"
      ],
      "metadata": {
        "id": "7ZThylEn8UwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#alternative: speech:\n",
        "#make training set with batch of 2 speech signals:\n",
        "batch=2;\n",
        "#fs, x0= wav.read('./audio/test2.wav') #get size of the speech files, all need to be identical\n",
        "x0, fs = librosa.load(\"./audio/Iron Maiden - The Number Of The Beast.mp3\", mono=True, sr=None, duration=6, offset=13)\n",
        "xlen=max(x0.shape)\n",
        "x=np.zeros((batch,xlen))\n",
        "for b in range(batch):\n",
        "    if b==0:\n",
        "        #fs, x0= wav.read('./audio/test2.wav')\n",
        "        x0, fs = librosa.load(\"./audio/Iron Maiden - The Number Of The Beast.mp3\", mono=True, sr=None, duration=6, offset=13)\n",
        "    if b==1:\n",
        "        #fs, x0= wav.read('./audio/test3.wav')\n",
        "        x0, fs = librosa.load(\"./audio/Iron Maiden - Aces High.mp3\", mono=True, sr=None, duration=6, offset=8)\n",
        "    x0= x0/max(x0)\n",
        "    x[b,:]=x0\n",
        "    #x=x*1.0/2**15 #normalize\n",
        "    print(\"x.shape=\", x.shape)\n",
        "    X=signal2pytorch(x).to(device) #Convert to pytorch format, batch is first dimension\n",
        "    print(\"X.shape=\", X.shape)\n",
        "    print(\"Generate Model:\")\n",
        "    model = Convautoenc().to(device)\n",
        "    print('Total number of parameters: %i' % (sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
        "    print(\"Def. loss function:\")\n",
        "    loss_fn = nn.MSELoss()  #MSE"
      ],
      "metadata": {
        "id": "-Rqwam0S8XVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ypred, Yencmean, Yencstd = model(X)\n",
        "\n",
        "#Ypred=Ypred.detach()\n",
        "outputlen=len(Ypred[0,0,:]) #length of the signal at the output of the network.\n",
        "print(\"outputlen=\", outputlen)\n",
        "\n",
        "Y=X[:,:,:outputlen]  #the target signal with same length as model output\n",
        "\n",
        "print(\"Input X.shape=\", X.shape )\n",
        "print(\"Target Y.shape=\", Y.shape)\n",
        "print(\"Target Y=\", Y)\n",
        "#print(\"max(max(Y))=\", max(max(max(Y))))\n",
        "#print(\"min(min(Y))=\", min(min(min(Y))))\n",
        "print(\"Y.type()=\", Y.type())\n",
        "\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)#, betas=(0.9, 0.999))\n",
        "\"\"\"\n",
        "try:\n",
        "    checkpoint = torch.load(\"audio_variational_autoenc.torch\",map_location='cpu')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    #optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "except IOError:\n",
        "    print(\"fresh start\")\n",
        "\"\"\"\n",
        "#optimrandomdir_pytorch.optimizer(model, loss_fn, X, Ypred, iterations=300, startingscale=1.0, endscale=0.0)\n",
        "#Ypred=model(X)\n",
        "#Ypred=Ypred.detach()\n",
        "#print(\"Ypred=\", Ypred)\n",
        "\n",
        "#randdir=True # True for optimization of random direction, False for pytorch optimization\n",
        "randdir=False"
      ],
      "metadata": {
        "id": "PCW_dAiu8fj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if randdir==True:\n",
        "    #optimization of weights using method of random directions:\n",
        "    optimrandomdir_pytorch.optimizer(model, loss_fn, X, Y, iterations=100000, startingscale=0.25, endscale=0.0)\n",
        "    #--End optimization of random directions------------------------\n",
        "else:\n",
        "    for epoch in range(2000):\n",
        "        #Ypred, Yencmean, Yencstd = model(X)\n",
        "        #mean values from the encoder network:\n",
        "        Yencmean=model.encodermean(X)\n",
        "\n",
        "        #standard deviation values from the network:\n",
        "        Yencstd=model.encoderstd(X)\n",
        "        #unit standard deviation:\n",
        "        #Yencstd=torch.ones(Yencmean.shape)\n",
        "\n",
        "        Yvariational= Yencmean + Yencstd*torch.randn_like(Yencstd)\n",
        "        Ypred=model.decoder(Yvariational)\n",
        "\n",
        "        mse=loss_fn(Ypred, Y)\n",
        "        #vl=variational_loss(Yencmean, Yencstd)\n",
        "        vl=variational_loss2(Yencmean, Yencstd)\n",
        "        loss= mse + 0.01*vl\n",
        "        #loss= mse\n",
        "        if epoch%10==0:\n",
        "             print(epoch, \"mse=\", mse.item(), \"variational loss=\", vl.item())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    #\"\"\"\n",
        "    torch.save({#'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()}, \"audio_variational_autoenc.torch\")\n",
        "    #\"\"\""
      ],
      "metadata": {
        "id": "Y7ljig3h8jgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MSE=\", loss_fn(Ypred, Y).item(), \"Variational Loss:\", variational_loss(Yencmean, Yencstd).item())\n",
        "ww = model.state_dict()   #read obtained weights\n",
        "print(\"ww=\", ww)\n",
        "#Plot obtained weights:\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(np.transpose(np.array(ww['conv1mean.weight'][0:1,0,:])))\n",
        "plt.plot(np.transpose(np.array(ww['conv1std.weight'][0:1,0,:])))\n",
        "plt.plot(np.transpose(np.array(ww['synconv1.weight'][0:1,0,:])))\n",
        "plt.legend(('Encoder Analysis filter 0, mean','Encoder Analysis filter 0, std', 'Decoder Filter 0'))\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Value')\n",
        "plt.title('The Encoder and Decoder Filter Coefficients')\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "RYNjGQz28nqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test on training set:\n",
        "\n",
        "#predictions=model(X).cpu() # Make Predictions based on the obtained weights, on training set\n",
        "#noisy case:\n",
        "#predictions, Yencmean, Yencstd = model(X)\n",
        "Yencmean=model.encodermean(X)\n",
        "\n",
        "#no noise case\n",
        "predclean=model.decoder(Yencmean)\n",
        "predclean=predclean.detach() #no noise case\n",
        "predclean=np.array(predclean)\n",
        "\n",
        "#Add gaussian noise with unit standard deviation to encoded signal:\n",
        "Yvariational= Yencmean + torch.randn_like(Yencmean)\n",
        "predictions=model.decoder(Yvariational)\n",
        "\n",
        "predictions=predictions.detach()\n",
        "predictions=np.array(predictions)\n",
        "Yencmean=np.array(Yencmean.detach())\n",
        "Yencstd=np.array(Yencstd.detach())\n",
        "print(\"Yencstd.shape=\",Yencstd.shape)\n",
        "\n",
        "Y=np.array(Y) #target\n",
        "#print(\"Y=\",Y)\n",
        "print(\"predictions.shape=\", predictions.shape)\n",
        "#convert to numpy:\n",
        "#https://discuss.pytorch.org/t/how-to-transform-variable-into-numpy/104/2"
      ],
      "metadata": {
        "id": "skAqfOBT8reS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd"
      ],
      "metadata": {
        "id": "hqD0Qhkz85ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot target signal and output of autoencoder:\n",
        "\n",
        "for b in range(batch):\n",
        "    #print(\"np.reshape(Yencstd[b,:,:],(1,-1))\", np.reshape(Yencstd[b,:,:],(1,-1)))\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.plot(np.reshape(Yencmean[b,:,:],(1,-1))[0,:])\n",
        "    plt.plot(np.reshape(Yencstd[b,:,:],(1,-1))[0,:])\n",
        "    plt.legend(('Encoded Mean', 'Encoded Standard Deviation'))\n",
        "    plt.title('The Encoded Domain, Mean and Standard Deviation')\n",
        "    plt.grid()\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.plot(np.array(Y[b,0,:]))\n",
        "    plt.plot(predictions[b,0,:])\n",
        "    plt.legend(('Target','Predicted'))\n",
        "    plt.title('The Target and Noisy Predicted Signal, batch '+str(b))\n",
        "    plt.xlabel('Sample')\n",
        "    plt.grid()\n",
        "\n",
        "    #No noise case:\n",
        "    xrek=predclean[b,0,:]  #remove unnecessary dimension for playback\n",
        "    xrek=np.clip(xrek, -1.0,1.0)\n",
        "    wav.write('testrekvaeclean'+str(b)+'.wav', fs, np.int16(2**15*xrek))\n",
        "    print('\"The training set output for clean encoded signal for batch'+str(b)+'\"')\n",
        "    display(ipd.Audio(2**15*xrek,rate=fs))\n",
        "\n",
        "    xrek=predictions[b,0,:]  #remove unnecessary dimension for playback\n",
        "    xrek=np.clip(xrek, -1.0,1.0)\n",
        "    wav.write('testrekvae'+str(b)+'.wav', fs, np.int16(2**15*xrek))\n",
        "    print('\"The training set output for noisy encoded signal for batch'+str(b)+'\"')\n",
        "    display(ipd.Audio(2**15*xrek,rate=fs))"
      ],
      "metadata": {
        "id": "d1SUyw_h80nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test on Verification set:\n",
        "#fs, x= wav.read('test.wav')\n",
        "x, fs = librosa.load(\"./audio/Iron Maiden - Aces High.mp3\", mono=True, sr=None, duration=6, offset=0)\n",
        "#fs, x= wav.read('test2.wav')\n",
        "#x=x*1.0/2**15 #normalize\n",
        "x=x/max(x)\n",
        "\n",
        "print(\"The verification set input to the variational autoencoder\")\n",
        "display(ipd.Audio(2**14*x,rate=fs))\n",
        "X=signal2pytorch(x).to(device)\n",
        "Yencmean=model.encodermean(X)\n",
        "\n",
        "predclean=model.decoder(Yencmean)\n",
        "predclean=predclean.detach() #no noise case\n",
        "predclean=np.array(predclean)\n",
        "\n",
        "#No noise case:\n",
        "xrek=predclean[0,0,:]  #remove unnecessary dimension for playback\n",
        "xrek=np.clip(xrek, -1.0,1.0)\n",
        "wav.write('testvervaeclean'+str(b)+'.wav', fs, np.int16(2**15*xrek))\n",
        "print(\"The verification set output for clean encoded signal\")\n",
        "display(ipd.Audio(2**15*xrek, rate=fs))\n",
        "\n",
        "#Add gaussian noise with unit standard deviation:\n",
        "Yvariational= Yencmean + torch.randn_like(Yencmean)\n",
        "predictions= model.decoder(Yvariational) # Make Predictions based on the obtained weights, on verification set\n",
        "predictions=predictions.detach()\n",
        "predictions=np.array(predictions)\n",
        "b=0\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(np.array(X[b,0,:]))\n",
        "plt.plot(predictions[b,0,:])\n",
        "plt.legend(('Original','Predicted'))\n",
        "plt.title('Verification, the Original and Predicted Signal, batch ')\n",
        "plt.xlabel('Sample')\n",
        "plt.grid()\n",
        "xrek=predictions[:,0,:]\n",
        "xrek=np.transpose(xrek)\n",
        "xrek=np.clip(xrek, -1.0,1.0)\n",
        "wav.write('testver.wav', fs, np.int16(2**15*xrek))\n",
        "print(\"The verification set output for noisy encoded signal\")\n",
        "display(ipd.Audio('testver.wav', rate=fs))\n",
        "print(\"Only noise as encoded signal\")\n",
        "\n",
        "Yvariational=  torch.randn_like(Yencmean)\n",
        "predictions= model.decoder(Yvariational) # Make Predictions based on the obtained weights, on verification set\n",
        "predictions=predictions.detach()\n",
        "predictions=np.array(predictions)\n",
        "xrek=predictions[:,0,:]\n",
        "xrek=np.transpose(xrek)\n",
        "xrek=np.clip(xrek, -1.0,1.0)\n",
        "wav.write('noisevarout.wav', fs, np.int16(2**15*xrek))\n",
        "print(\"The decoded signal\")\n",
        "display(ipd.Audio('noisevarout.wav', rate=fs))"
      ],
      "metadata": {
        "id": "AEAas3OT88YV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Eksperimen 3**"
      ],
      "metadata": {
        "id": "MBLsS3RU9IfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#alternative: speech:\n",
        "#make training set with batch of 2 speech signals:\n",
        "batch=2;\n",
        "#fs, x0= wav.read('./audio/test2.wav') #get size of the speech files, all need to be identical\n",
        "x0, fs = librosa.load(\"./audio/Iron Maiden - The Number Of The Beast.mp3\", mono=True, sr=None, duration=6, offset=13)\n",
        "xlen=max(x0.shape)\n",
        "x=np.zeros((batch,xlen))\n",
        "for b in range(batch):\n",
        "    if b==0:\n",
        "        #fs, x0= wav.read('./audio/test2.wav')\n",
        "        x0, fs = librosa.load(\"./audio/Iron Maiden - The Number Of The Beast.mp3\", mono=True, sr=None, duration=6, offset=13)\n",
        "    if b==1:\n",
        "        #fs, x0= wav.read('./audio/test3.wav')\n",
        "        x0, fs = librosa.load(\"./audio/Iron Maiden - Aces High.mp3\", mono=True, sr=None, duration=6, offset=8)\n",
        "    x0= x0/max(x0)\n",
        "    x[b,:]=x0\n",
        "    #x=x*1.0/2**15 #normalize\n",
        "    print(\"x.shape=\", x.shape)\n",
        "    X=signal2pytorch(x).to(device) #Convert to pytorch format, batch is first dimension\n",
        "    print(\"X.shape=\", X.shape)\n",
        "    print(\"Generate Model:\")\n",
        "    model = Convautoenc().to(device)\n",
        "    print('Total number of parameters: %i' % (sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
        "    print(\"Def. loss function:\")\n",
        "    loss_fn = nn.MSELoss()  #MSE"
      ],
      "metadata": {
        "id": "Ynpe6vOq9LgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ypred, Yencmean, Yencstd = model(X)\n",
        "\n",
        "#Ypred=Ypred.detach()\n",
        "outputlen=len(Ypred[0,0,:]) #length of the signal at the output of the network.\n",
        "print(\"outputlen=\", outputlen)\n",
        "\n",
        "Y=X[:,:,:outputlen]  #the target signal with same length as model output\n",
        "\n",
        "print(\"Input X.shape=\", X.shape )\n",
        "print(\"Target Y.shape=\", Y.shape)\n",
        "print(\"Target Y=\", Y)\n",
        "#print(\"max(max(Y))=\", max(max(max(Y))))\n",
        "#print(\"min(min(Y))=\", min(min(min(Y))))\n",
        "print(\"Y.type()=\", Y.type())\n",
        "\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)#, betas=(0.9, 0.999))\n",
        "\"\"\"\n",
        "try:\n",
        "    checkpoint = torch.load(\"audio_variational_autoenc.torch\",map_location='cpu')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    #optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "except IOError:\n",
        "    print(\"fresh start\")\n",
        "\"\"\"\n",
        "#optimrandomdir_pytorch.optimizer(model, loss_fn, X, Ypred, iterations=300, startingscale=1.0, endscale=0.0)\n",
        "#Ypred=model(X)\n",
        "#Ypred=Ypred.detach()\n",
        "#print(\"Ypred=\", Ypred)\n",
        "\n",
        "#randdir=True # True for optimization of random direction, False for pytorch optimization\n",
        "randdir=False"
      ],
      "metadata": {
        "id": "CklvGw0l9R5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if randdir==True:\n",
        "    #optimization of weights using method of random directions:\n",
        "    optimrandomdir_pytorch.optimizer(model, loss_fn, X, Y, iterations=100000, startingscale=0.25, endscale=0.0)\n",
        "    #--End optimization of random directions------------------------\n",
        "else:\n",
        "    for epoch in range(2000):\n",
        "        #Ypred, Yencmean, Yencstd = model(X)\n",
        "        #mean values from the encoder network:\n",
        "        Yencmean=model.encodermean(X)\n",
        "\n",
        "        #standard deviation values from the network:\n",
        "        #Yencstd=model.encoderstd(X)\n",
        "        #unit standard deviation:\n",
        "        Yencstd=torch.ones(Yencmean.shape)\n",
        "\n",
        "        Yvariational= Yencmean + Yencstd*torch.randn_like(Yencstd)\n",
        "        Ypred=model.decoder(Yvariational)\n",
        "\n",
        "        mse=loss_fn(Ypred, Y)\n",
        "        #vl=variational_loss(Yencmean, Yencstd)\n",
        "        vl=variational_loss2(Yencmean, Yencstd)\n",
        "        loss= mse + 0*vl\n",
        "        #loss= mse\n",
        "        if epoch%10==0:\n",
        "             print(epoch, \"mse=\", mse.item(), \"variational loss=\", vl.item())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    #\"\"\"\n",
        "    torch.save({#'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()}, \"audio_variational_autoenc.torch\")\n",
        "    #\"\"\"\n"
      ],
      "metadata": {
        "id": "qHup_6VW9WQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MSE=\", loss_fn(Ypred, Y).item(), \"Variational Loss:\", variational_loss(Yencmean, Yencstd).item())\n",
        "ww = model.state_dict()   #read obtained weights\n",
        "print(\"ww=\", ww)\n",
        "#Plot obtained weights:\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(np.transpose(np.array(ww['conv1mean.weight'][0:1,0,:])))\n",
        "plt.plot(np.transpose(np.array(ww['conv1std.weight'][0:1,0,:])))\n",
        "plt.plot(np.transpose(np.array(ww['synconv1.weight'][0:1,0,:])))\n",
        "plt.legend(('Encoder Analysis filter 0, mean','Encoder Analysis filter 0, std', 'Decoder Filter 0'))\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Value')\n",
        "plt.title('The Encoder and Decoder Filter Coefficients')\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "jPK3PH0I9Zqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test on training set:\n",
        "\n",
        "#predictions=model(X).cpu() # Make Predictions based on the obtained weights, on training set\n",
        "#noisy case:\n",
        "#predictions, Yencmean, Yencstd = model(X)\n",
        "Yencmean=model.encodermean(X)\n",
        "\n",
        "#no noise case\n",
        "predclean=model.decoder(Yencmean)\n",
        "predclean=predclean.detach() #no noise case\n",
        "predclean=np.array(predclean)\n",
        "\n",
        "#Add gaussian noise with unit standard deviation to encoded signal:\n",
        "Yvariational= Yencmean + torch.randn_like(Yencmean)\n",
        "predictions=model.decoder(Yvariational)\n",
        "\n",
        "predictions=predictions.detach()\n",
        "predictions=np.array(predictions)\n",
        "Yencmean=np.array(Yencmean.detach())\n",
        "Yencstd=np.array(Yencstd.detach())\n",
        "print(\"Yencstd.shape=\",Yencstd.shape)\n",
        "\n",
        "Y=np.array(Y) #target\n",
        "#print(\"Y=\",Y)\n",
        "print(\"predictions.shape=\", predictions.shape)\n",
        "#convert to numpy:\n",
        "#https://discuss.pytorch.org/t/how-to-transform-variable-into-numpy/104/2"
      ],
      "metadata": {
        "id": "5q8uNQ-s9coE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd"
      ],
      "metadata": {
        "id": "NS3RrqF69fNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot target signal and output of autoencoder:\n",
        "\n",
        "for b in range(batch):\n",
        "    #print(\"np.reshape(Yencstd[b,:,:],(1,-1))\", np.reshape(Yencstd[b,:,:],(1,-1)))\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.plot(np.reshape(Yencmean[b,:,:],(1,-1))[0,:])\n",
        "    plt.plot(np.reshape(Yencstd[b,:,:],(1,-1))[0,:])\n",
        "    plt.legend(('Encoded Mean', 'Encoded Standard Deviation'))\n",
        "    plt.title('The Encoded Domain, Mean and Standard Deviation')\n",
        "    plt.grid()\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.plot(np.array(Y[b,0,:]))\n",
        "    plt.plot(predictions[b,0,:])\n",
        "    plt.legend(('Target','Predicted'))\n",
        "    plt.title('The Target and Noisy Predicted Signal, batch '+str(b))\n",
        "    plt.xlabel('Sample')\n",
        "    plt.grid()\n",
        "\n",
        "    #No noise case:\n",
        "    xrek=predclean[b,0,:]  #remove unnecessary dimension for playback\n",
        "    xrek=np.clip(xrek, -1.0,1.0)\n",
        "    wav.write('testrekvaeclean'+str(b)+'.wav', fs, np.int16(2**15*xrek))\n",
        "    print('\"The training set output for clean encoded signal for batch'+str(b)+'\"')\n",
        "    display(ipd.Audio(2**15*xrek,rate=fs))\n",
        "\n",
        "    xrek=predictions[b,0,:]  #remove unnecessary dimension for playback\n",
        "    xrek=np.clip(xrek, -1.0,1.0)\n",
        "    wav.write('testrekvae'+str(b)+'.wav', fs, np.int16(2**15*xrek))\n",
        "    print('\"The training set output for noisy encoded signal for batch'+str(b)+'\"')\n",
        "    display(ipd.Audio(2**15*xrek,rate=fs))"
      ],
      "metadata": {
        "id": "kMPMoF9s9iJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test on Verification set:\n",
        "#fs, x= wav.read('test.wav')\n",
        "x, fs = librosa.load(\"./audio/Iron Maiden - Aces High.mp3\", mono=True, sr=None, duration=6, offset=0)\n",
        "#fs, x= wav.read('test2.wav')\n",
        "#x=x*1.0/2**15 #normalize\n",
        "x=x/max(x)\n",
        "\n",
        "print(\"The verification set input to the variational autoencoder\")\n",
        "display(ipd.Audio(2**14*x,rate=fs))\n",
        "X=signal2pytorch(x).to(device)\n",
        "Yencmean=model.encodermean(X)\n",
        "\n",
        "predclean=model.decoder(Yencmean)\n",
        "predclean=predclean.detach() #no noise case\n",
        "predclean=np.array(predclean)\n",
        "\n",
        "#No noise case:\n",
        "xrek=predclean[0,0,:]  #remove unnecessary dimension for playback\n",
        "xrek=np.clip(xrek, -1.0,1.0)\n",
        "wav.write('testvervaeclean'+str(b)+'.wav', fs, np.int16(2**15*xrek))\n",
        "print(\"The verification set output for clean encoded signal\")\n",
        "display(ipd.Audio(2**15*xrek, rate=fs))\n",
        "\n",
        "#Add gaussian noise with unit standard deviation:\n",
        "Yvariational= Yencmean + torch.randn_like(Yencmean)\n",
        "predictions= model.decoder(Yvariational) # Make Predictions based on the obtained weights, on verification set\n",
        "predictions=predictions.detach()\n",
        "predictions=np.array(predictions)\n",
        "b=0\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(np.array(X[b,0,:]))\n",
        "plt.plot(predictions[b,0,:])\n",
        "plt.legend(('Original','Predicted'))\n",
        "plt.title('Verification, the Original and Predicted Signal, batch ')\n",
        "plt.xlabel('Sample')\n",
        "plt.grid()\n",
        "xrek=predictions[:,0,:]\n",
        "xrek=np.transpose(xrek)\n",
        "xrek=np.clip(xrek, -1.0,1.0)\n",
        "wav.write('testver.wav', fs, np.int16(2**15*xrek))\n",
        "print(\"The verification set output for noisy encoded signal\")\n",
        "display(ipd.Audio('testver.wav', rate=fs))\n",
        "print(\"Only noise as encoded signal\")\n",
        "\n",
        "Yvariational=  torch.randn_like(Yencmean)\n",
        "predictions= model.decoder(Yvariational) # Make Predictions based on the obtained weights, on verification set\n",
        "predictions=predictions.detach()\n",
        "predictions=np.array(predictions)\n",
        "xrek=predictions[:,0,:]\n",
        "xrek=np.transpose(xrek)\n",
        "xrek=np.clip(xrek, -1.0,1.0)\n",
        "wav.write('noisevarout.wav', fs, np.int16(2**15*xrek))\n",
        "print(\"The decoded signal\")\n",
        "display(ipd.Audio('noisevarout.wav', rate=fs))"
      ],
      "metadata": {
        "id": "Uep-2uT69n5q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}